{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing Jaccard and word2vec similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import similarities.loading as sl\n",
    "import resources.dataset as rd\n",
    "import resources.queries as rq\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Aminer Citation Network Datasets - v1 and v9](https://aminer.org/citation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_path = \"resources/aminer/v1\"\n",
    "data_path = \"resources/aminer/v9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select related documents or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "related_docs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content for n_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_documents = 10\n",
    "# Load document ids in the Same order than the matrices\n",
    "# indexdocs = rd.get_sample_ids(data_path, related_docs=related_docs)\n",
    "indexdocs = []\n",
    "# Index \n",
    "ix_data = rq.cur_indexed_docs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = 0\n",
    "i = 0\n",
    "result = rq.find_all_indexdoc(ix_data, \" \".join(indexdocs))\n",
    "for r in result:\n",
    "    i += 1\n",
    "    len_title = len(r['title'].split())\n",
    "    len_content = len(r['content'].split())\n",
    "    total_len += (len_content - len_title)\n",
    "# print(total_len/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200000 8 8 2862584 14.31292\n",
      "400000 7 178 11682970 29.207425\n",
      "600000 10 191 24202688 40.33781333333334\n",
      "800000 6 147 42529170 53.1614625\n",
      "1000000 12 176 66014922 66.014922\n",
      "1200000 6 92 91274833 76.06236083333333\n",
      "1400000 11 160 116654040 83.32431428571428\n",
      "1600000 5 80 143540550 89.71284375\n",
      "1800000 10 90 169911897 94.39549833333334\n",
      "2000000 12 151 196330182 98.165091\n",
      "2200000 8 161 223937602 101.78981909090909\n",
      "96.44732212412089\n",
      "Standard deviation: 0.06245114832450417\n",
      "84.40083008517148\n"
     ]
    }
   ],
   "source": [
    "with ix_data.reader() as reader:\n",
    "    i = 0\n",
    "    total_len = 0\n",
    "    for docid in reader.all_doc_ids():\n",
    "        doc = reader.stored_fields(docid)\n",
    "        len_title = len(doc['title'].split())\n",
    "        len_content = len(doc['content'].split())\n",
    "        i += 1\n",
    "        total_len += (len_content - len_title)\n",
    "        if i % 200000 == 0: \n",
    "            print(i, len_title, len_content, total_len, total_len/i)\n",
    "    mean = total_len/i\n",
    "    print(mean)\n",
    "    \n",
    "    total = 0\n",
    "    for docid in reader.all_doc_ids():\n",
    "        doc = reader.stored_fields(docid)\n",
    "        len_title = len(doc['title'].split())\n",
    "        len_content = len(doc['content'].split())\n",
    "        total = ((len_content - len_title) - mean)**2\n",
    "    s = np.sqrt(total/(i-1))\n",
    "    print(\"Standard deviation:\", s)\n",
    "    print(mean - mean*s*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(indexdocs_ordered_word2vec[:n_documents])\n",
    "for idoc in indexdocs[:n_documents]:\n",
    "    result = rq.find_indexdoc(ix_data, idoc)\n",
    "    for r in result:\n",
    "        print(r['indexdoc'], \"\\t\", r['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(indexdocs_ordered_word2vec[:n_documents])\n",
    "for idoc in indexdocs[-n_documents:]:\n",
    "    result = rq.find_indexdoc(ix_data, idoc)\n",
    "    for r in result:\n",
    "        print(r['indexdoc'], \"\\t\", r['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for //: 'list' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-6c2a65698776>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexdocs\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindexdocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mn_documents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_indexdoc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mix_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'indexdoc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'content'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for //: 'list' and 'int'"
     ]
    }
   ],
   "source": [
    "offset = indexdocs//2\n",
    "for idoc in indexdocs[offset:offset+n_documents]:\n",
    "    result = rq.find_indexdoc(ix_data, idoc)\n",
    "    for r in result:\n",
    "        print(r['indexdoc'], \"\\t\", r['content'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
