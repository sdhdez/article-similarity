{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: SemEval 2017 Task 10 corpus doesn't exists.\n",
      "    - Download from here https://scienceie.github.io/resources.html\n",
      "    - Use one of the following paths.\n",
      "        + ./kleis_data/corpus/semeval2017-task10/\n",
      "        + ~/kleis_data/corpus/semeval2017-task10/\n",
      "        + /home/snov/environments/artsim/lib/python3.6/site-packages/kleis/kleis_data/corpus/semeval2017-task10/\n",
      "    - You can use pre-trained models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default:  ~/kleis_data/corpus/semeval2017-task10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "# Counter\n",
    "from collections import Counter\n",
    "import kleis.resources.dataset as kl\n",
    "# Package\n",
    "import somhos.resources.dataset as rd\n",
    "import somhos.resources.queries as rq\n",
    "import somhos.methods.useful as mu\n",
    "from somhos.methods.useful import save_pickle, load_pickle\n",
    "from somhos.config.paths import get_relative_path\n",
    "from somhos.config.paths import DOCS_SAMPLE_A_SUFFIX, DOCS_SAMPLE_B_SUFFIX, DOCS_SAMPLES_CONTENT\n",
    "from somhos.config.paths import SAMPLE_PATH, DOCS_SAMPLES_WORD_COUNT, DOCS_SAMPLES_WORD_DOC_COUNT\n",
    "from somhos.config.paths import DOCS_SAMPLES_KPS_COUNT, DOCS_SAMPLES_KPS_DOC_COUNT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../src/somhos/resources/aminer/v9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load module to tag keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kleis = kl.load_corpus()\n",
    "kleis.training(features_method=\"simple-posseq\", filter_min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples size: (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "# Load sample A\n",
    "docs_sample_a_path = get_relative_path(data_path, DOCS_SAMPLE_A_SUFFIX)\n",
    "docs_sample_a = load_pickle(docs_sample_a_path)\n",
    "# Load sample B\n",
    "docs_sample_b_path = get_relative_path(data_path, DOCS_SAMPLE_B_SUFFIX)\n",
    "docs_sample_b = load_pickle(docs_sample_b_path)\n",
    "\n",
    "print(\"Samples size: (%d, %d)\" % (len(docs_sample_a), len(docs_sample_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Init cursor\n",
    "ix_data = rq.cur_indexed_docs(data_path)\n",
    "# Get analizer\n",
    "analizer = rd.get_default_analizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bag of words and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples_content = {}\n",
    "samples_kps_count = Counter()\n",
    "samples_kps_in_docs_count = Counter()\n",
    "samples_words_count = Counter()\n",
    "samples_word_in_docs_count = Counter()\n",
    "for i, result in enumerate(rq.find_all_indexdoc(ix_data, \" \".join(docs_sample_a + docs_sample_b))):\n",
    "    # get bag of words\n",
    "    title_len = len(result['title']) + 1\n",
    "    tokens = [t.text for t in analizer(result['content'])]\n",
    "    bag_of_words = set(tokens)\n",
    "    # get keyphrases\n",
    "    text = result['title'].strip(\". \") + \". \" + result['content']\n",
    "    keyphrases = kleis.label_text(text)\n",
    "    kps_normalized = [mu.lower_utf8(kptext) for _, _, kptext in keyphrases]\n",
    "    # kps_hashes = [mu.hash_16bytes(mu.lower_utf8(kptext)) for _, _, kptext in keyphrases]\n",
    "    bag_of_kps = set(kps_normalized)\n",
    "    # Counts\n",
    "    samples_words_count.update(tokens)\n",
    "    samples_word_in_docs_count.update(bag_of_words)\n",
    "    samples_kps_count.update(kps_normalized)\n",
    "    samples_kps_in_docs_count.update(bag_of_kps)\n",
    "    # Doc content\n",
    "    samples_content[result['indexdoc']] = {'title': result['title'], \n",
    "                                           'text': result['content'],\n",
    "                                           'content': result['content'][title_len:],\n",
    "                                           'bag-of-words': bag_of_words,\n",
    "                                           'bag-of-kps': bag_of_kps\n",
    "                                          }\n",
    "total_word_count = sum(samples_words_count.values())\n",
    "word_counts = {'total': total_word_count, 'count': samples_words_count}\n",
    "total_kps_count = sum(samples_kps_count.values())\n",
    "kps_counts = {'total': total_kps_count, 'count': samples_kps_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_content_path = get_relative_path(data_path, DOCS_SAMPLES_CONTENT)\n",
    "save_pickle(samples_content, docs_samples_content_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 2000\n",
      "290051 [('based', 1946), ('data', 1720), ('which', 1401), ('system', 1370), ('using', 1335), ('model', 1233), ('paper', 1098), ('our', 1067), ('method', 1019), ('time', 992)]\n",
      "[('based', 977), ('paper', 911), ('which', 876), ('using', 810), ('results', 745), ('system', 611), ('used', 603), ('such', 598), ('data', 590), ('these', 589)]\n",
      "57677 [(b'algorithm', 275), (b'system', 239), (b'data', 224), (b'simulation', 221), (b'algorithms', 175), (b'problem', 158), (b'performance', 153), (b'solution', 141), (b'users', 135), (b'xml', 126)]\n",
      "[(b'algorithm', 184), (b'system', 161), (b'data', 157), (b'simulation', 151), (b'algorithms', 122), (b'problem', 122), (b'performance', 119), (b'addition', 112), (b'solution', 105), (b'users', 89)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Docs: %d\" % (i + 1))\n",
    "print(total_word_count, samples_words_count.most_common(10))\n",
    "print(samples_word_in_docs_count.most_common(10))\n",
    "print(total_kps_count, samples_kps_count.most_common(10))\n",
    "print(samples_kps_in_docs_count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_word_count_path = get_relative_path(data_path, DOCS_SAMPLES_WORD_COUNT)\n",
    "save_pickle(word_counts, docs_samples_word_count_path)\n",
    "\n",
    "docs_samples_word_doc_count_path = get_relative_path(data_path, DOCS_SAMPLES_WORD_DOC_COUNT)\n",
    "save_pickle(samples_word_in_docs_count, docs_samples_word_doc_count_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_kps_count_path = get_relative_path(data_path, DOCS_SAMPLES_KPS_COUNT)\n",
    "save_pickle(kps_counts, docs_samples_kps_count_path)\n",
    "\n",
    "docs_samples_kps_doc_count_path = get_relative_path(data_path, DOCS_SAMPLES_KPS_DOC_COUNT)\n",
    "save_pickle(samples_kps_in_docs_count, docs_samples_kps_doc_count_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
