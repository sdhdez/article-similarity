{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: SemEval 2017 Task 10 corpus doesn't exists.\n",
      "    - Download from here https://scienceie.github.io/resources.html\n",
      "    - Use one of the following paths.\n",
      "        + ./kleis_data/corpus/semeval2017-task10/\n",
      "        + ~/kleis_data/corpus/semeval2017-task10/\n",
      "        + /home/snov/environments/artsim/lib/python3.6/site-packages/kleis/kleis_data/corpus/semeval2017-task10/\n",
      "    - You can use pre-trained models.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default:  ~/kleis_data/corpus/semeval2017-task10\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "# Counter\n",
    "from collections import Counter\n",
    "import kleis.resources.dataset as kl\n",
    "# Package\n",
    "import somhos.resources.dataset as rd\n",
    "import somhos.resources.queries as rq\n",
    "import somhos.methods.useful as mu\n",
    "from somhos.methods.useful import save_pickle, load_pickle\n",
    "from somhos.config.paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_path = \"../../\"\n",
    "data_path = get_relative_path(prefix_path, V9GAMMA_PATH)\n",
    "os.path.exists(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load module to tag keyphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "kleis = kl.load_corpus()\n",
    "kleis.training(features_method=\"simple-posseq\", filter_min_count=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples size: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Load sample A\n",
    "docs_sample_a_path = get_relative_path(data_path, DOCS_SAMPLE_A_SUFFIX)\n",
    "docs_sample_a = load_pickle(docs_sample_a_path)\n",
    "# Load sample B\n",
    "docs_sample_b_path = get_relative_path(data_path, DOCS_SAMPLE_B_SUFFIX)\n",
    "docs_sample_b = load_pickle(docs_sample_b_path)\n",
    "\n",
    "print(\"Samples size: (%d, %d)\" % (len(docs_sample_a), len(docs_sample_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Init cursor\n",
    "ix_data = rq.cur_indexed_docs(data_path)\n",
    "# Get analizer\n",
    "analizer = rd.get_default_analizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get bag of words and counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples_content = {}\n",
    "samples_kps_count = Counter()\n",
    "samples_kps_in_docs_count = Counter()\n",
    "samples_words_count = Counter()\n",
    "samples_word_in_docs_count = Counter()\n",
    "for i, result in enumerate(rq.find_all_indexdoc(ix_data, \" \".join(docs_sample_a + docs_sample_b))):\n",
    "    # get bag of words\n",
    "    title_len = len(result['title']) + 1\n",
    "    tokens = [t.text for t in analizer(result['content'])]\n",
    "    bag_of_words = set(tokens)\n",
    "    # get keyphrases\n",
    "    text = result['title'].strip(\". \") + \". \" + result['content']\n",
    "    keyphrases = kleis.label_text(text)\n",
    "    kps_normalized = [mu.lower_utf8(kptext) for _, _, kptext in keyphrases]\n",
    "    # kps_hashes = [mu.hash_16bytes(mu.lower_utf8(kptext)) for _, _, kptext in keyphrases]\n",
    "    bag_of_kps = set(kps_normalized)\n",
    "    # Counts\n",
    "    samples_words_count.update(tokens)\n",
    "    samples_word_in_docs_count.update(bag_of_words)\n",
    "    samples_kps_count.update(kps_normalized)\n",
    "    samples_kps_in_docs_count.update(bag_of_kps)\n",
    "    # Doc content\n",
    "    samples_content[result['indexdoc']] = {'title': result['title'], \n",
    "                                           'text': result['content'],\n",
    "                                           'content': result['content'][title_len:],\n",
    "                                           'tokens': tokens,\n",
    "                                           'kps-normalized': kps_normalized,\n",
    "                                           'bag-of-words': bag_of_words,\n",
    "                                           'bag-of-kps': bag_of_kps\n",
    "                                          }\n",
    "total_word_count = sum(samples_words_count.values())\n",
    "word_counts = {'total': total_word_count, 'count': samples_words_count}\n",
    "total_kps_count = sum(samples_kps_count.values())\n",
    "kps_counts = {'total': total_kps_count, 'count': samples_kps_count}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_content_path = get_relative_path(data_path, DOCS_SAMPLES_CONTENT)\n",
    "save_pickle(samples_content, docs_samples_content_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 10000\n",
      "1455421 [('based', 9616), ('data', 7719), ('which', 7254), ('system', 7222), ('model', 6649), ('using', 6515), ('paper', 5579), ('time', 5476), ('our', 4781), ('results', 4779)]\n",
      "[('based', 4990), ('paper', 4700), ('which', 4516), ('using', 3992), ('results', 3581), ('system', 3123), ('also', 3077), ('such', 3073), ('used', 3043), ('has', 3031)]\n",
      "289305 [(b'algorithm', 1259), (b'system', 1163), (b'data', 1012), (b'simulation', 975), (b'algorithms', 845), (b'users', 710), (b'book', 691), (b'solution', 672), (b'information', 661), (b'problem', 570)]\n",
      "[(b'algorithm', 841), (b'system', 831), (b'data', 756), (b'simulation', 732), (b'algorithms', 565), (b'solution', 512), (b'addition', 509), (b'users', 493), (b'problem', 459), (b'information', 458)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Docs: %d\" % (i + 1))\n",
    "print(total_word_count, samples_words_count.most_common(10))\n",
    "print(samples_word_in_docs_count.most_common(10))\n",
    "print(total_kps_count, samples_kps_count.most_common(10))\n",
    "print(samples_kps_in_docs_count.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_word_count_path = get_relative_path(data_path, DOCS_SAMPLES_WORD_COUNT)\n",
    "save_pickle(word_counts, docs_samples_word_count_path)\n",
    "\n",
    "docs_samples_word_doc_count_path = get_relative_path(data_path, DOCS_SAMPLES_WORD_DOC_COUNT)\n",
    "save_pickle(samples_word_in_docs_count, docs_samples_word_doc_count_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_kps_count_path = get_relative_path(data_path, DOCS_SAMPLES_KPS_COUNT)\n",
    "save_pickle(kps_counts, docs_samples_kps_count_path)\n",
    "\n",
    "docs_samples_kps_doc_count_path = get_relative_path(data_path, DOCS_SAMPLES_KPS_DOC_COUNT)\n",
    "save_pickle(samples_kps_in_docs_count, docs_samples_kps_doc_count_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
