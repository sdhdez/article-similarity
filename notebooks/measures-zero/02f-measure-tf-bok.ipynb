{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "# Counter\n",
    "from collections import Counter\n",
    "# Package\n",
    "import somhos.resources.dataset as rd\n",
    "import somhos.resources.queries as rq\n",
    "from somhos.methods.useful import save_pickle, load_pickle, wordvectors_centroid\n",
    "from somhos.config.paths import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix_path = \"../../\"\n",
    "data_path = get_relative_path(prefix_path, V9GAMMA_PATH)\n",
    "os.path.exists(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples size: (5000, 5000)\n"
     ]
    }
   ],
   "source": [
    "# Load sample A\n",
    "docs_sample_a_path = get_relative_path(data_path, DOCS_SAMPLE_A_SUFFIX)\n",
    "docs_sample_a = load_pickle(docs_sample_a_path)\n",
    "# Load sample B\n",
    "docs_sample_b_path = get_relative_path(data_path, DOCS_SAMPLE_B_SUFFIX)\n",
    "docs_sample_b = load_pickle(docs_sample_b_path)\n",
    "\n",
    "print(\"Samples size: (%d, %d)\" % (len(docs_sample_a), len(docs_sample_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load samples content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Docs: 10000\n"
     ]
    }
   ],
   "source": [
    "docs_samples_content_path = get_relative_path(data_path, DOCS_SAMPLES_CONTENT)\n",
    "samples_content = load_pickle(docs_samples_content_path)\n",
    "print(\"Docs: %d\" % len(samples_content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import cosine as cosine_distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load counts documents by keyprase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_samples_kps_count_path = get_relative_path(data_path, DOCS_SAMPLES_KPS_COUNT)\n",
    "samples_kps_count = load_pickle(docs_samples_kps_count_path)\n",
    "Vlen = len(samples_kps_count['count'])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "print(Vlen)\n",
    "vocabulary = []\n",
    "inv_vocabulary = {}\n",
    "for i, w in enumerate(samples_kps_count['count'].keys()):\n",
    "    vocabulary.append(w)\n",
    "    inv_vocabulary[w] = i\n",
    "print(list(samples_kps_count['count'].keys())[:10])\n",
    "print(len(vocabulary))\n",
    "print(len(inv_vocabulary))\n",
    "print(inv_vocabulary[b'presented'])\n",
    "print(vocabulary[inv_vocabulary[b'presented']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02326211 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.02326211 0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "sample_a_indices = range(0, len(docs_sample_a))\n",
    "sample_b_indices = range(0, len(docs_sample_b))\n",
    "\n",
    "def get_content_for(index, samples_content, field='kps-normalized'):\n",
    "    return samples_content[index][field]\n",
    "\n",
    "def tf_doc(terms):\n",
    "    tf = Counter(terms)\n",
    "    cnt = sum(tf.values())\n",
    "    return {k: v/cnt for k, v in tf.items()}\n",
    "\n",
    "m_measure_sim = np.zeros([len(docs_sample_a), len(docs_sample_b)])\n",
    "for i in range(0, len(sample_a_indices)):\n",
    "    # Term frequencies by document\n",
    "    tf_a_dict = tf_doc(get_content_for(docs_sample_a[i], samples_content))\n",
    "    for j in range(0, len(sample_b_indices)):\n",
    "        # Term frequencies by document\n",
    "        tf_b_dict = tf_doc(get_content_for(docs_sample_b[j], samples_content))\n",
    "        # Term list\n",
    "        t_list = list(set(tf_a_dict) | set(tf_b_dict))\n",
    "        # TF\n",
    "        tf_a = np.zeros([len(t_list),])\n",
    "        tf_b = np.zeros([len(t_list),])  \n",
    "        for pos, t in enumerate(t_list):\n",
    "            if t in tf_a_dict:\n",
    "                tf_a[pos] = tf_a_dict[t]\n",
    "            if t in tf_b_dict:\n",
    "                tf_b[pos] = tf_b_dict[t]\n",
    "        # Measure\n",
    "        measure_sim = 1.0 - cosine_distance(tf_a, tf_b)\n",
    "        if measure_sim != 0:\n",
    "            m_measure_sim[i, j] = measure_sim\n",
    "print(m_measure_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_path = get_relative_path(data_path, DOCS_SAMPLES_TF_KPS)\n",
    "save_pickle(m_measure_sim, pickle_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
