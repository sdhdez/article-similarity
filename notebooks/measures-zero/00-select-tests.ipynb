{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select sample of documents with keyphrases from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import random\n",
    "from somhos.methods.useful import save_pickle, load_pickle\n",
    "from somhos.config.paths import get_relative_path\n",
    "from somhos.config.paths import DOCS_SAMPLE_A_SUFFIX, DOCS_SAMPLE_B_SUFFIX, KPS_DIRECTORY_INVERSE_SUFFIX, SAMPLE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Default path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../../src/somhos/resources/aminer/v9\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load test dataset ids to select a sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test dataset:  243520\n"
     ]
    }
   ],
   "source": [
    "test_dataset_path = data_path + \"/test-dataset.pkl\"\n",
    "test_dataset = load_pickle(test_dataset_path)\n",
    "print(\"Test dataset: \", len(test_dataset), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load inverse directory 'document id -> keyphrase ids' to check if document has keyphrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inverse directory:  1475448\n"
     ]
    }
   ],
   "source": [
    "kps_directory_inverse_path = get_relative_path(data_path, KPS_DIRECTORY_INVERSE_SUFFIX)\n",
    "kps_directory_inverse = load_pickle(kps_directory_inverse_path)\n",
    "print(\"Inverse directory: \", len(kps_directory_inverse), file=sys.stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select two samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected documents: 2000\n",
      "0 243520 0.00821287779237845\n",
      "Samples size: (1000, 1000)\n"
     ]
    }
   ],
   "source": [
    "seed = 0\n",
    "# docs with keyphrases\n",
    "docs_wkps = len(test_dataset)\n",
    "# n expected docs\n",
    "ndocs_expected = (1000*2)\n",
    "print(\"Expected documents: %d\" % ndocs_expected)\n",
    "# threshold\n",
    "threshold = ndocs_expected/docs_wkps\n",
    "print(seed, docs_wkps, threshold)\n",
    "# Init seed\n",
    "random.seed(0)\n",
    "# Select random docs\n",
    "docs_set_a = set()\n",
    "docs_set_b = set()\n",
    "def insert_to_set(element, set_1, set_2, limit):\n",
    "    \"\"\"Insert element to the first set not exceding limit\"\"\"\n",
    "    if len(set_1) < limit and element not in set_2:\n",
    "        set_1.add(element)\n",
    "    elif len(set_2) < limit and element not in set_1:\n",
    "        set_2.add(element)\n",
    "\n",
    "# while not ndocs_expected selected\n",
    "test_dataset_iter = iter(test_dataset)\n",
    "while len(docs_set_a | docs_set_b) < ndocs_expected:\n",
    "    # iter test dataset\n",
    "    try:\n",
    "        cur_doc = next(test_dataset_iter)\n",
    "    except StopIteration:\n",
    "        test_dataset_iter = iter(test_dataset)\n",
    "    # if doc not in inverse_directory\n",
    "    if cur_doc not in kps_directory_inverse:\n",
    "        continue\n",
    "    if len(kps_directory_inverse[cur_doc]) < 5:\n",
    "        continue\n",
    "    # if greater than threshold\n",
    "    if random.random() > threshold:\n",
    "        continue\n",
    "    # assign doc randomly\n",
    "    if random.random() <= 0.5:\n",
    "        insert_to_set(cur_doc, docs_set_a, docs_set_b, ndocs_expected/2)\n",
    "    else:\n",
    "        insert_to_set(cur_doc, docs_set_b, docs_set_a, ndocs_expected/2)\n",
    "print(\"Samples size: (%d, %d)\" % (len(docs_set_a), len(docs_set_b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del kps_directory_inverse\n",
    "del test_dataset_iter\n",
    "del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_sample_path = get_relative_path(data_path, SAMPLE_PATH)\n",
    "if not os.path.exists(docs_sample_path):\n",
    "    os.mkdir(docs_sample_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save sample A\n",
    "docs_sample_a_path = get_relative_path(data_path, DOCS_SAMPLE_A_SUFFIX)\n",
    "save_pickle(list(docs_set_a), docs_sample_a_path)\n",
    "# Save sample B\n",
    "docs_sample_b_path = get_relative_path(data_path, DOCS_SAMPLE_B_SUFFIX)\n",
    "save_pickle(list(docs_set_b), docs_sample_b_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
