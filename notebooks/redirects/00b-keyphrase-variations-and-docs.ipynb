{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from somhos.config.paths import *\n",
    "from somhos.methods.useful import save_pickle, load_pickle\n",
    "import somhos.methods.useful as mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_path = '../../'\n",
    "data_path = get_relative_path(prefix_path, V9GAMMA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11523073\n"
     ]
    }
   ],
   "source": [
    "page_rds = load_pickle(get_relative_path(prefix_path, PAGE_REDIRECTS))\n",
    "print(len(page_rds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11523073\n"
     ]
    }
   ],
   "source": [
    "page_inverse_dict = load_pickle(get_relative_path(prefix_path, PAGE_INVERSE_DICT))\n",
    "print(len(page_inverse_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922202\n"
     ]
    }
   ],
   "source": [
    "keyphrases_directory = load_pickle(get_relative_path(data_path, KPS_DIRECTORY_SUFFIX))\n",
    "print(len(keyphrases_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922202\n"
     ]
    }
   ],
   "source": [
    "keyphrases_normalized = load_pickle(get_relative_path(data_path, KPS_NORMALIZED_SUFFIX))\n",
    "print(len(keyphrases_normalized))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load set of keyphrases (extracted with kleis) intersecting the set of Wikipedia pages and generate distinct representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218637\n",
      "218637\n",
      "218637\n"
     ]
    }
   ],
   "source": [
    "hashes_intersection = load_pickle(get_relative_path(prefix_path, HASHES_INTERSECTION))\n",
    "print(len(hashes_intersection))\n",
    "\n",
    "def hash2str(h):\n",
    "    return keyphrases_normalized[keyphrases_directory[h]].decode('utf-8')\n",
    "\n",
    "def str2id(s):\n",
    "    return page_inverse_dict[s]\n",
    "\n",
    "str_intersection = set(hash2str(h) for h in hashes_intersection) # - manually_ignored \n",
    "print(len(str_intersection))\n",
    "\n",
    "id_intersection = set(str2id(s) for s in str_intersection)\n",
    "print(len(id_intersection))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%reset_selective -f page_inverse_dict\n",
    "%reset_selective -f keyphrases_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load all posible redirect pages in wikipedia from the ids in the intersection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150968\n"
     ]
    }
   ],
   "source": [
    "redirects = set(rd for str_id in id_intersection for rd in page_rds[str_id])\n",
    "print(len(redirects))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load more resoruces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3394754\n"
     ]
    }
   ],
   "source": [
    "redirect_pages = load_pickle(get_relative_path(prefix_path, REDIRECT_PAGES))\n",
    "print(len(redirect_pages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract sets of wikipedia pages for each redirect and made their intersection with the hashes_intersection.\n",
    "Filtering redirects with more than 1 page variation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{5008150, 9437190},\n",
       " {7340040, 8422844},\n",
       " {3670036, 5516775},\n",
       " {2888303, 5222676, 6208933, 9399802, 10333801},\n",
       " {1373481, 2011089, 3407894},\n",
       " {6024825, 6815768},\n",
       " {6194474, 11128015},\n",
       " {4574384, 4980774, 8096396},\n",
       " {3493224, 7864378},\n",
       " {5767228, 7679608},\n",
       " {60207, 5689252},\n",
       " {7584300, 11343008},\n",
       " {6815812, 7801572, 9621095, 10000434},\n",
       " {786503, 1298591, 3747683},\n",
       " {3407947, 11053787},\n",
       " {790906, 4289511, 8240332},\n",
       " {4718684, 5066569},\n",
       " {102, 6698828},\n",
       " {1048686, 9740537},\n",
       " {1773639,\n",
       "  3250187,\n",
       "  5598451,\n",
       "  6217961,\n",
       "  6815869,\n",
       "  8921108,\n",
       "  8925409,\n",
       "  8956352,\n",
       "  10274254,\n",
       "  11152431}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyphrase_variations = list(filter(lambda x: len(x) > 1, [redirect_pages[rd] & id_intersection for rd in redirects]))\n",
    "print(len(keyphrase_variations))\n",
    "keyphrase_variations[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset_selective -f redirect_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'collections': 20237, 'collected': 2176, 'uncollectable': 0},\n",
       " {'collections': 1839, 'collected': 894, 'uncollectable': 0},\n",
       " {'collections': 23, 'collected': 50, 'uncollectable': 0}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3922202\n"
     ]
    }
   ],
   "source": [
    "keyphrases_dir_docid = load_pickle(get_relative_path(data_path, KPS_DOCS_IDS_SUFFIX))\n",
    "print(len(keyphrases_dir_docid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11523073\n"
     ]
    }
   ],
   "source": [
    "page_dictionary = load_pickle(get_relative_path(prefix_path, PAGE_DICTIONARY))\n",
    "print(len(page_dictionary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125735\n",
      "52132\n"
     ]
    }
   ],
   "source": [
    "def str2docids(s):\n",
    "    h = mu.hash_16bytes(s.encode('utf-8'))\n",
    "    return keyphrases_dir_docid[keyphrases_directory[h]]\n",
    "\n",
    "page_docids = {}\n",
    "rd_docids = defaultdict(set)\n",
    "for pgs in keyphrase_variations:\n",
    "    for p in pgs:\n",
    "        s = page_dictionary[p]\n",
    "        page_docids[p] = str2docids(s)\n",
    "        for r in page_rds[p]:\n",
    "            rd_docids[r] |= page_docids[p]\n",
    "print(len(page_docids))\n",
    "print(len(rd_docids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('donorschoose', {'index1561736', 'index2374450'}),\n",
       " ('wl', {'index1291962', 'index2327088', 'index2378558', 'index2381491'}),\n",
       " ('welcomelong',\n",
       "  {'index2264700', 'index2327088', 'index2378558', 'index2381491'})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list((page_dictionary[k], v) for k, v in rd_docids.items()), key=lambda x: x[1], reverse=True)[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9437190, {'index1561736'}),\n",
       " (5008150, {'index2374450'}),\n",
       " (7340040, {'index2327088', 'index2378558', 'index2381491'})]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(page_docids.items())[:3]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# %reset_selective -f keyphrases_dir_docid\n",
    "%reset_selective -f keyphrases_directory\n",
    "%reset_selective -f page_rds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'collections': 25671, 'collected': 2176, 'uncollectable': 0},\n",
       " {'collections': 2332, 'collected': 894, 'uncollectable': 0},\n",
       " {'collections': 25, 'collected': 50, 'uncollectable': 0}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "gc.get_stats()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "del page_dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of keyphrases and the set of documents in which they appears but with only one representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('vlachos', {'index952783'}), ('vlachou', {'index1183044'})],\n",
       " [('respiratory sinus arrhythmia', {'index1907846'}),\n",
       "  ('sinus arrhythmia', {'index1398573'})]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kpvariations_nointersection = []\n",
    "for kvs in keyphrase_variations:\n",
    "    docids = set()\n",
    "    for p in kvs:\n",
    "        docids = page_docids[p].symmetric_difference(docids)\n",
    "    symmdiff_docs = list(filter(lambda x: len(x[1]) > 0, [(p, page_docids[p] & docids) for p in kvs]))\n",
    "    kpvariations_nointersection.append(symmdiff_docs)\n",
    "# force to more than one variation\n",
    "kpvariations_nointersection = list(filter(lambda x: len(x) > 1, kpvariations_nointersection))\n",
    "print(len(kpvariations_nointersection))\n",
    "list([(page_dictionary[rd], docs) for rd, docs in rds] for rds in kpvariations_nointersection)[10:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_pickle(kpvariations_nointersection, get_relative_path(prefix_path, KEYPHRASEVARIATIONS_DOCS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151404\n"
     ]
    }
   ],
   "source": [
    "doc_groups = defaultdict(set) \n",
    "for i, grp in enumerate(kpvariations_nointersection):\n",
    "    for keyphrase, docset in grp:\n",
    "        for d in docset:\n",
    "            doc_groups[d].add(i)\n",
    "doc_groups = sorted(doc_groups.items(), key=lambda x: len(x[1]), reverse=True)\n",
    "print(len(doc_groups))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "group_docs = defaultdict(set)\n",
    "for d, gprs in doc_groups[:20]:\n",
    "    for g in gprs:\n",
    "        group_docs[g].add(d)\n",
    "group_docs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "docids_pages = defaultdict(set)\n",
    "docids_rds = defaultdict(set)\n",
    "for doc_group in not_intersected_docs[:20]:\n",
    "    for kp, docs in doc_group:\n",
    "        for d in docs:\n",
    "            docids_rds[d] |= set(page_dictionary[p] for p in page_rds[kp])\n",
    "            docids_pages[d].add(page_dictionary[kp])\n",
    "            # print(kp, d, docids_pages[d])\n",
    "# docids_pages = dict(filter(lambda x: len(x[1]) > 1, docids_pages.items()))\n",
    "print(len(docids_pages))\n",
    "print(len(docids_rds))\n",
    "# docids_rds\n",
    "# list(docids_pages.items())[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
